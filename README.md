# *Projeto AprovAI ‚Äî Predi√ß√£o Antecipada de Risco de Reprova√ß√£o*

O *AprovAI* √© um projeto que utiliza t√©cnicas de Machine Learning para prever o risco de reprova√ß√£o de estudantes antes da divulga√ß√£o da nota final (G3).
O objetivo √© permitir que escolas e professores identifiquem alunos em risco e possam agir de forma preventiva, oferecendo refor√ßo, apoio e interven√ß√µes pedag√≥gicas.

---

# *1. Introdu√ß√£o*

O projeto busca responder a uma necessidade comum em ambientes educacionais:

> *√â poss√≠vel prever se um aluno ser√° aprovado ou reprovado antes do fim do per√≠odo letivo?*

Com base em dados de desempenho parcial (G1, G2) e vari√°veis sociais/comportamentais, treinamos modelos para antecipar o resultado final ‚Äî permitindo interven√ß√µes mais r√°pidas e eficazes.

---

# *2. Defini√ß√£o do Problema*

O desafio principal √©:

*Prever se um aluno ser√° aprovado (ou reprovado) antes que a nota final G3 seja conhecida.*

Essa previs√£o antecipada ajuda em:

* Monitoramento de risco
* Redu√ß√£o de reprova√ß√£o e evas√£o
* A√ß√µes preventivas e refor√ßo direcionado
* Suporte pedag√≥gico individualizado

---

# *3. Descri√ß√£o da Base de Dados*

O projeto utiliza duas bases do Kaggle (Maths e Portuguese):

*Dataset:* [https://www.kaggle.com/datasets/whenamancodes/student-performance/data](https://www.kaggle.com/datasets/whenamancodes/student-performance/data)

As bases cont√™m originalmente *33 vari√°veis* com informa√ß√µes pessoais, familiares, comportamentais e acad√™micas.

## *3.1. Vis√£o Geral das Categorias*

### *a) Informa√ß√µes pessoais e familiares*

Incluem:

* sex, age, address, famsize, Pstatus
* Escolaridade dos pais: Medu, Fedu
* Ocupa√ß√£o dos pais: Mjob, Fjob
* Rela√ß√µes familiares: famrel, guardian, famsup

### *b) H√°bitos e rotina escolar*

Informa√ß√µes sobre comportamento:

* studytime, traveltime, freetime
* goout (socializa√ß√£o)
* Dalc, Walc (consumo de √°lcool)
* absences (faltas)

### *c) Notas*

* G1 ‚Äî nota do 1¬∫ per√≠odo
* G2 ‚Äî nota do 2¬∫ per√≠odo
* G3 ‚Äî nota final

---

## *3.2. Sele√ß√£o das Colunas Usadas no Modelo*

O projeto utiliza exatamente as colunas preparadas por:

python
def preparar_df(df, nome):
    colunas = [
        "G1", "G2",
        "traveltime", "freetime", "studytime",
        "absences", "famsize", "Pstatus",
        "G3"
    ]


### *Colunas utilizadas no treinamento*

| Tipo                   | Colunas                               | Justificativa                                      |
| ---------------------- | ------------------------------------- | -------------------------------------------------- |
| *Desempenho parcial* | G1, G2                            | S√£o os melhores preditores da nota final.          |
| *Rotina escolar*     | studytime, traveltime, freetime | Medem dedica√ß√£o, tempo livre e deslocamento.       |
| *Frequ√™ncia*         | absences                            | Faltas est√£o fortemente ligadas a reprova√ß√£o.      |
| *Contexto familiar*  | famsize, Pstatus                  | Indicadores sociais que podem impactar desempenho. |
| *Desempenho final*   | G3                                  | Usada apenas para criar o target.                  |

---

## *3.3. Cria√ß√£o da Vari√°vel-Alvo (Target)*

A coluna *G3* √© usada para gerar a coluna *aprovado*, usada pelos modelos:

* *1 = aprovado (G3 ‚â• 10)*
* *0 = reprovado (G3 < 10)*

Ap√≥s isso, *G3 √© removida* do conjunto de treinamento, simulando previs√£o antecipada.

Isso significa:

> O modelo aprende com G1, G2 e vari√°veis sociais para tentar prever se o aluno ser√° aprovado antes da nota final existir.

---

# *4. Pr√©-processamento*

O pipeline de prepara√ß√£o inclui:

## *4.1. Sele√ß√£o das colunas mais relevantes*

Escolhemos um conjunto enxuto e eficiente:

* G1, G2
* studytime, traveltime, freetime
* absences, famsize, Pstatus

## *4.2. Convers√£o de vari√°veis categ√≥ricas*

Vari√°veis como famsize e Pstatus s√£o transformadas via:

python
LabelEncoder()


Isso √© necess√°rio para que os modelos consigam operar sobre vari√°veis textuais.

## *4.3. Divis√£o em treino e teste*

A base √© dividida em:

* *80% treino*
* *20% teste*

Usando:

python
train_test_split(..., random_state=42)


Garantindo reprodutibilidade dos resultados.

---

# *5. Modelos Utilizados*

Dois modelos de Machine learning cl√°ssicos e eficazes foram utilizados KNN e Arv√≥re de decis√£o.
Um modelo de Rede Neural MLPClassifier (Multi-layer Perceptron).

---

## *5.1. KNN ‚Äî K-Nearest Neighbors*

### Como funciona:

Classifica um novo aluno com base nos alunos mais ‚Äúparecidos‚Äù com ele.

### Etapas realizadas:

* Padroniza√ß√£o de vari√°veis (StandardScaler)
* Treinamento com KNN
* Avalia√ß√£o por:

  * Acur√°cia
  * Relat√≥rio de Classifica√ß√£o
  * Matriz de Confus√£o
* Gr√°ficos de dispers√£o para compreender rela√ß√µes entre vari√°veis

### Motivos para uso:

* Simples de entender
* Boa performance em datasets menores
* Ajuda a visualizar padr√µes globais

---

## *5.2. √Årvore de Decis√£o*

### Como funciona:

Cria regras do tipo:


Se G2 < 10 ‚Üí risco alto
Se absences > 8 ‚Üí risco moderado
...


### Etapas realizadas:

* Treinamento com DecisionTreeClassifier
* Visualiza√ß√£o da √°rvore com plot_tree
* Avalia√ß√£o com:

  * Acur√°cia
  * Relat√≥rio de classifica√ß√£o
  * Matriz de confus√£o

### Por que usar:

* Muito interpret√°vel
* R√°pida
* Mostra import√¢ncia das vari√°veis
* Permite compreender decis√µes como um professor faria

---

## *5.3. Rede Neural de Classifica√ß√£o*

### Como funciona:

A Rede Neural Multilayer Perceptron (MLP) aprende padr√µes combinando v√°rias camadas de neur√¥nios artificiais.
Ela identifica rela√ß√µes n√£o lineares entre notas, comportamento e vari√°veis sociais, ajustando seus pesos durante o treinamento para melhorar a precis√£o da previs√£o de aprova√ß√£o.

### Etapas realizadas:
* Padroniza√ß√£o das vari√°veis num√©ricas (StandardScaler)
* Codifica√ß√£o de vari√°veis categ√≥ricas (OneHotEncoder)
* Constru√ß√£o do modelo com duas camadas ocultas (64 e 32 neur√¥nios)
* Treinamento usando Pipeline
* Avalia√ß√£o com:

    * Acur√°cia
    * Relat√≥rio de classifica√ß√£o
    * Precis√£o, Recall e F1-Score
    * Matriz de Confus√£o

* C√°lculo da probabilidade de aprova√ß√£o para cada aluno

### Por que usar:
* Aprende padr√µes mais complexos que modelos lineares
* Funciona bem com dados mistos (num√©ricos e categ√≥ricos)
* Capta rela√ß√µes n√£o lineares entre vari√°veis
* Gera tamb√©m a probabilidade de aprova√ß√£o, n√£o s√≥ a classe
* Boa op√ß√£o quando muitos fatores influenciam o desempenho
---

# *6. Resultados Obtidos*

---

## *6.1. Machine Learning*

De forma geral, os resultados foram consistentes entre as duas bases e ambos modelos:

### *Acur√°cia m√©dia:* entre *0.65 e 0.75*

### Principais achados:

* A classe *aprovado* √© mais f√°cil de prever
* A classe *reprovado* sofre com desbalanceamento (poucos casos)
* G2 √© a vari√°vel mais importante para ambos os modelos
* Faltas (absences) tamb√©m t√™m impacto relevante
* Fatores sociais t√™m influ√™ncia menor, por√©m existente

### Gr√°ficos produzidos:

* Dispers√£o por vari√°vel (KNN)
* Matriz de confus√£o
* √Årvore de decis√£o completa

---

## *6.2.Rede Neural*

Os resultados da rede neural foram est√°veis e pr√≥ximos aos modelos tradicionais, mostrando boa capacidade de generaliza√ß√£o.

### *Acur√°cia m√©dia:* entre *0.70 e 0.78*

### Principais achados:

* A rede neural identificou bem a classe aprovado
* A classe reprovado continuou mais dif√≠cil devido ao desbalanceamento
* As vari√°veis G1 e G2 foram as mais influentes no processo de classifica√ß√£o
* Faltas (absences) tamb√©m contribu√≠ram de forma relevante
* Vari√°veis sociais apresentaram influ√™ncia menor, mas ajudaram a melhorar o ajuste

### Gr√°ficos produzidos:

* Matriz de confus√£o
* Relat√≥rio de classifica√ß√£o
* Probabilidade individual de aprova√ß√£o para cada aluno

---

# *7. Conclus√µes*

* *G1 e G2* s√£o excelentes preditores do desempenho final.
* *√Årvore de decis√£o* √© a melhor op√ß√£o para interpretar e justificar decis√µes.
* *KNN* funciona, mas pode ser sens√≠vel √† escala e aos dados categ√≥ricos.
* *A Rede Neural (MLP)*  obteve desempenho ligeiramente superior e capturou padr√µes mais complexos, mostrando-se √∫til para prever risco de reprova√ß√£o de forma antecipada.
* Fatores sociais funcionam como complementos, n√£o determinantes.
* O modelo √© √∫til para identificar alunos em risco antes do fechamento das notas.

---

# *8. Pr√≥ximos Passos*

Para evoluir o projeto:

### üîπ Refinamento de modelos

* Ajuste de hiperpar√¢metros (GridSearch)
* Uso de class_weight='balanced'

### üîπ Modelos adicionais

* Random Forest
* Regress√£o Log√≠stica
* SVM

### üîπ Melhorias no pipeline

* Balanceamento da base (SMOTE)
* An√°lise de correla√ß√£o aprofundada

### üîπ Interface pr√°tica

* Criar ferramenta online (Flask, Streamlit ou Gradio)
* Permitir aos professores testar alunos individualmente
