# -*- coding: utf-8 -*-
"""MachineLearning_Classificação_ArvoreDecisao_KNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yOU3NyR7dxh3uSDaVb-QpzLGJeWo4uqP
"""

#!pip install pandas scikit-learn seaborn matplotlib

# 1. Importação de bibliotecas

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import sys
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

sns.set(style="whitegrid")
pd.options.display.max_columns = 200
print("Imports carregados com sucesso.")

# Carrega dados de forma segura - conferencia

def carregar_dataset(path):
    print(f"\n[LOAD] Carregando: {path}")
    df = pd.read_csv(path, encoding="latin1")
    print("[LOAD] Colunas detectadas:")
    print(df.columns.tolist())
    return df

df_mat = carregar_dataset("/content/Maths.csv")
df_por = carregar_dataset("/content/Portuguese.csv")

# Função para seleção e preparo das colunas pertinentes

def preparar_df(df, nome):
    print(f"\n[PREP] - Dataset de {nome}")

    colunas = [
        "G1", "G2",
        "traveltime", "freetime", "studytime",
        "absences", "famsize", "Pstatus",
        "G3"
    ]

    df = df[colunas].copy()

    # Label encoding para Pstatus e famsize
    cat_cols = ["Pstatus", "famsize"]

    le = LabelEncoder()
    for c in cat_cols:
        df[c] = le.fit_transform(df[c])

    print(df.head())

    return df

df_mat_prep = preparar_df(df_mat, "Matemática")
df_por_prep = preparar_df(df_por, "Português")

# Função para imprimir métricas e gráficos

def avaliar_modelo(y_test, y_pred, titulo):
    print(f"RESULTADOS — {titulo}")
    print("Acurácia:", accuracy_score(y_test, y_pred))
    print("\nClassification Report:")
    print(classification_report(y_test, y_pred))

    # Matriz de confusão
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(5,4))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
    plt.title(f"Matriz de Confusão — {titulo}")
    plt.xlabel("Previsto")
    plt.ylabel("Real")
    plt.show()

# Função para preparar X e y

def separar_xy(df):
    X = df.drop(columns=["G3"])
    y = df["G3"].apply(lambda x: 1 if x >= 10 else 0)  # classificar G3
    return X, y

X_mat, y_mat = separar_xy(df_mat_prep)
X_por, y_por = separar_xy(df_por_prep)

print("Math — X:", X_mat.shape, "y:", y_mat.shape)
print("Portuguese — X:", X_por.shape, "y:", y_por.shape)

"""#KNN"""

# Função para treinar KNN

def treinar_knn(X, y, nome):
    print(f"\n================== KNN — {nome} ==================")

    # divisão
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42
    )

    # normalização
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # modelo
    knn = KNeighborsClassifier()
    knn.fit(X_train_scaled, y_train)

    # previsões
    y_pred = knn.predict(X_test_scaled)

    # avaliação
    avaliar_modelo(y_test, y_pred, f"KNN — {nome}")

    # gráficos de dispersão
    for i in range(X_train_scaled.shape[1]):
        plt.figure(figsize=(5,4))
        plt.scatter(X_train_scaled[:, i], y_train, c=y_train, cmap="viridis")
        plt.title(f"{nome} — {X.columns[i]} vs Target")
        plt.xlabel(X.columns[i])
        plt.ylabel("Aprovado (0/1)")
        plt.show()

# Executar KNN
treinar_knn(X_mat, y_mat, "Matemática")

# Executar KNN
treinar_knn(X_por, y_por, "Português")

"""# ÁRVORE DE DECISÃO

"""

# Função para Árvore de Decisão


def treinar_arvore(X, y, nome):
    print(f"\n================== ÁRVORE — {nome} ==================")

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42
    )

    dt = DecisionTreeClassifier(max_depth=6, random_state=42)
    dt.fit(X_train, y_train)

    y_pred = dt.predict(X_test)

    avaliar_modelo(y_test, y_pred, f"Árvore — {nome}")

    # plot da árvore
    plt.figure(figsize=(22,10))
    plot_tree(dt, filled=True, feature_names=X.columns, class_names=["Reprovado","Aprovado"])
    plt.title(f"Árvore de Decisão — {nome}")
    plt.show()

# Executar Árvore
treinar_arvore(X_mat, y_mat, "Matemática")

# Executar Árvore
treinar_arvore(X_por, y_por, "Português")